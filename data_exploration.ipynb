{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import elasticsearch.helpers\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 documents found\n"
     ]
    }
   ],
   "source": [
    "# Find top10\n",
    "res = es.search(index='facebook', doc_type='user', body= {'query': {'match': {'gender': 'female'}}})\n",
    "print(\"%d documents found\" % res['hits']['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    }
   ],
   "source": [
    "# Take all result\n",
    "users = list(elasticsearch.helpers.scan(es, index='facebook', doc_type='user'))\n",
    "total_user = [(user['_id'], user['_source'].get('gender')) for user in users]\n",
    "print(len(total_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_message = ['1618047998214350', '1624029027647185', '1454298984658260']\n",
    "foreigners = ['1695358370488750', '10213401737335928', '1532260126834371', '10154597524691479', '10155404471078548', '10158882655745234']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = {'male': [], 'female': []}\n",
    "for user in total_user:\n",
    "    if user[0] not in (no_message + foreigners):\n",
    "        if user[1] == 'male':\n",
    "            user_dict['male'].append(user[0])\n",
    "        else:\n",
    "            user_dict['female'].append(user[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male: 80\n",
      "female: 54\n"
     ]
    }
   ],
   "source": [
    "print('male: ' + str(len(user_dict['male'])) + '\\nfemale: ' + str(len(user_dict['female'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping user posts\n",
    "def get_posts(users):\n",
    "    posts_dic = {}\n",
    "    for user in users:\n",
    "        # print(user)\n",
    "        posts = list(elasticsearch.helpers.scan(es, query={'query': {'match': {'user_id': user}}}, index='facebook', doc_type='post'))\n",
    "        message = [post['_source'].get('message') for post in posts if post['_source'].get('message') != '']\n",
    "        #print(message)\n",
    "        posts_dic[user] = message\n",
    "    return posts_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_posts_dict = get_posts(user_dict['male'])\n",
    "female_posts_dict = get_posts(user_dict['female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if content is Chinese or not\n",
    "def is_Chinese(uchar):\n",
    "    if uchar >= u'\\u4e00' and uchar<=u'\\u9fa5':  \n",
    "        return True  \n",
    "    else:  \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using jieba to tokenize user posts\n",
    "def tokenize_posts(user_posts):\n",
    "    seg_posts = {}\n",
    "    for key, messages in user_posts.items():\n",
    "        seg_posts[key] = [\" \".join(jieba.cut(message, cut_all = False)) for message in messages]\n",
    "    return seg_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_seg_posts = tokenize_posts(male_posts_dict)\n",
    "female_seg_posts = tokenize_posts(female_posts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [segment for key, segments in female_seg_posts.items() for segment in segments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(vectorizer, tfidf_result):\n",
    "    # http://stackoverflow.com/questions/16078015/\n",
    "    scores = zip(vectorizer.get_feature_names(),\n",
    "                 np.asarray(tfidf_result.sum(axis=0)).ravel())\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    index_scores = []\n",
    "    for index, item in enumerate(sorted_scores):\n",
    "        index_scores.append((index, item[1]))\n",
    "    return sorted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tfidf(seg_posts):\n",
    "    corpus += segments for key, segments in seg_posts.items()\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "    tfidf_features = tfidf_vectorizer.get_feature_names()\n",
    "    \n",
    "    sorted_scores = display_scores(tfidf_vectorizer, tfidf)\n",
    "    return sorted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = [word[0] for word in sorted_scores[:198]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['真的',\n",
       " '今天',\n",
       " '可以',\n",
       " '自己',\n",
       " '我們',\n",
       " '大家',\n",
       " '什麼',\n",
       " '一個',\n",
       " '還是',\n",
       " 'com',\n",
       " '怎麼',\n",
       " '知道',\n",
       " '就是',\n",
       " '不要',\n",
       " 'http',\n",
       " '哈哈',\n",
       " '謝謝',\n",
       " '覺得',\n",
       " '一起',\n",
       " '哈哈哈',\n",
       " '不是',\n",
       " '這麼',\n",
       " 'xd',\n",
       " '開心',\n",
       " '這樣',\n",
       " '時候',\n",
       " '一直',\n",
       " '看到',\n",
       " '這個',\n",
       " '一下',\n",
       " 'www',\n",
       " '明天',\n",
       " '希望',\n",
       " '感覺',\n",
       " '有人',\n",
       " '開始',\n",
       " '因為',\n",
       " '快樂',\n",
       " '好像',\n",
       " '喜歡',\n",
       " '好吃',\n",
       " '朋友',\n",
       " '沒有',\n",
       " '還有',\n",
       " '雖然',\n",
       " '有點',\n",
       " '現在',\n",
       " '時間',\n",
       " '所以',\n",
       " '很多',\n",
       " '回家',\n",
       " '一樣',\n",
       " '感謝',\n",
       " '但是',\n",
       " '想要',\n",
       " '我要',\n",
       " 'plurk',\n",
       " '剛剛',\n",
       " '一定',\n",
       " '如果',\n",
       " '晚餐',\n",
       " '加油',\n",
       " '最近',\n",
       " '發現',\n",
       " '不會',\n",
       " '其實',\n",
       " '天氣',\n",
       " '分享',\n",
       " 'youtube',\n",
       " '需要',\n",
       " '不能',\n",
       " '只是',\n",
       " '原來',\n",
       " '好多',\n",
       " '可是',\n",
       " '不過',\n",
       " 'watch',\n",
       " '台灣',\n",
       " '好久',\n",
       " '東西',\n",
       " 'the',\n",
       " '第一次',\n",
       " '好好',\n",
       " 'https',\n",
       " '生活',\n",
       " 'to',\n",
       " '一天',\n",
       " '老師',\n",
       " '他們',\n",
       " '人生',\n",
       " '已經',\n",
       " '真是',\n",
       " '只有',\n",
       " 'xdd',\n",
       " '到底',\n",
       " '生日',\n",
       " '這是',\n",
       " 'qq',\n",
       " 'you',\n",
       " '小孩',\n",
       " '一點',\n",
       " 'xddd',\n",
       " '應該',\n",
       " '你們',\n",
       " '那麼',\n",
       " '回來',\n",
       " '竟然',\n",
       " '世界',\n",
       " '一次',\n",
       " '不想',\n",
       " '照片',\n",
       " '結果',\n",
       " '台北',\n",
       " '一年',\n",
       " '努力',\n",
       " '幸福',\n",
       " '畢業',\n",
       " '事情',\n",
       " '10',\n",
       " '心情',\n",
       " '突然',\n",
       " '想到',\n",
       " '媽媽',\n",
       " '每天',\n",
       " 'ya',\n",
       " '出來',\n",
       " '可能',\n",
       " '一種',\n",
       " '重要',\n",
       " '地方',\n",
       " 'my',\n",
       " '期待',\n",
       " '昨天',\n",
       " '每次',\n",
       " '準備',\n",
       " '看電影',\n",
       " '午餐',\n",
       " '小心',\n",
       " '晚上',\n",
       " '非常',\n",
       " '不用',\n",
       " '一切',\n",
       " '終於',\n",
       " '遇到',\n",
       " '每個',\n",
       " '早上',\n",
       " '快來',\n",
       " '起來',\n",
       " '以前',\n",
       " '只能',\n",
       " '正在',\n",
       " '厲害',\n",
       " '結束',\n",
       " '安排',\n",
       " '未來',\n",
       " '這種',\n",
       " '繼續',\n",
       " '是不是',\n",
       " '完全',\n",
       " 'so',\n",
       " '活動',\n",
       " '兩個',\n",
       " '不到',\n",
       " '根本',\n",
       " '參加',\n",
       " '而且',\n",
       " '哈哈哈哈',\n",
       " '工作',\n",
       " 'and',\n",
       " '入學',\n",
       " '宿舍',\n",
       " '收入',\n",
       " '親愛的',\n",
       " '孩子',\n",
       " '睡覺',\n",
       " '名學生',\n",
       " '學雜費',\n",
       " '今年',\n",
       " 'love',\n",
       " '別人',\n",
       " '看看',\n",
       " '手機',\n",
       " '出門',\n",
       " '感動',\n",
       " '果然',\n",
       " '居然',\n",
       " '一些',\n",
       " 'it',\n",
       " 'in',\n",
       " '打卡',\n",
       " '可怕',\n",
       " '記得',\n",
       " '日子',\n",
       " '下次',\n",
       " '大學',\n",
       " '就要',\n",
       " '我覺',\n",
       " '我會']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
